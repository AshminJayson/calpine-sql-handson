{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2ca6d9",
   "metadata": {
    "vscode": {
     "languageId": "groovy"
    }
   },
   "source": [
    "# EXPLORATORY DATA ANALYSIS (EDA) - OVERVIEW & PANDAS FUNCTIONS\n",
    "\n",
    "EDA is a critical step in the data science process that helps us understand our dataset \n",
    "before applying machine learning algorithms or statistical models.\n",
    "\n",
    "KEY OBJECTIVES OF EDA:\n",
    "1. Understand the structure and characteristics of the data\n",
    "2. Identify missing values, outliers, and data quality issues\n",
    "3. Discover patterns, trends, and relationships in the data\n",
    "4. Generate hypotheses for further analysis\n",
    "5. Inform data preprocessing and feature engineering decisions\n",
    "\n",
    "ESSENTIAL PANDAS FUNCTIONS FOR EDA:\n",
    "\n",
    "1. DATA OVERVIEW:\n",
    "    - df.head() / df.head(n)     → View first n rows (default 5)\n",
    "    - df.tail() / df.tail(n)     → View last n rows (default 5)\n",
    "    - df.sample(n)               → View n random rows\n",
    "    - df.shape                   → Get dimensions (rows, columns)\n",
    "    - df.columns                 → List all column names\n",
    "    - df.info()                  → Data types, memory usage, non-null counts\n",
    "    - df.dtypes                  → Data types of each column\n",
    "\n",
    "2. STATISTICAL SUMMARY:\n",
    "    - df.describe()              → Summary statistics for numerical columns\n",
    "    - df.describe(include='all') → Summary statistics for all columns\n",
    "    - df.nunique()               → Count unique values per column\n",
    "    - df.value_counts()          → Frequency count of unique values\n",
    "\n",
    "3. DATA QUALITY ASSESSMENT:\n",
    "    - df.isnull().sum()          → Count missing values per column\n",
    "    - df.isna().sum()            → Alternative to isnull()\n",
    "    - df.duplicated().sum()      → Count duplicate rows\n",
    "    - df.drop_duplicates()       → Remove duplicate rows\n",
    "\n",
    "4. DATA EXPLORATION:\n",
    "    - df.groupby().agg()         → Group data and apply aggregations\n",
    "    - df.corr()                  → Correlation matrix for numerical columns\n",
    "    - df.crosstab()              → Cross-tabulation for categorical variables\n",
    "    - df.pivot_table()           → Create pivot tables\n",
    "\n",
    "5. DATA VISUALIZATION (with pandas plotting):\n",
    "    - df.plot()                  → Basic line plot\n",
    "    - df.hist()                  → Histograms for all numerical columns\n",
    "    - df.boxplot()               → Box plots for outlier detection\n",
    "    - df.plot.scatter()          → Scatter plots for relationships\n",
    "\n",
    "CURRENT DATASET INSIGHTS:\n",
    "- Dataset contains 525 rows and 18 columns\n",
    "- Multiple data types: numerical (Age, Purchase Amount, etc.) and categorical (Gender, Category, etc.)\n",
    "- Significant missing values across most columns (ranging from 8-48 missing values per column)\n",
    "- Mixed case inconsistencies in Gender column ('Male', 'female', 'Female')\n",
    "- Some critical columns like Customer ID have missing values (39 missing)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df: pd.DataFrame = pd.read_csv('customer_purchase_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View random 5 rows\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc00bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View last 5 rows\n",
    "df.tail(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ab30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row and column count\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d693105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()\n",
    "# df.describe(include='all')\n",
    "\n",
    "# include = 'all' to include categorical columns as well otherwise only numerical columns are considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e243be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1bb864",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8efa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50418aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all records with any column having null values\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Data Analysis\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a51ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure same casing for all categorical columns\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].str.title()\n",
    "    # print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip leading/trailing spaces\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "    # print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ee4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove typo in Yess for Yes in 'Subscription Status' column\n",
    "df['Subscription Status'] = df['Subscription Status'].replace(\"Yess\", \"Yes\")\n",
    "df['Subscription Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cdc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review Rating'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df69356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review Rating'] = df['Review Rating'].replace(\"Five\", 5)\n",
    "\n",
    "# Convert to float\n",
    "df['Review Rating'] = pd.to_numeric(df['Review Rating'], errors='coerce')\n",
    "df['Review Rating'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70074b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Purchase Amount (USD)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f069279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove purchase amounts with negative values\n",
    "df = df[df['Purchase Amount (USD)'] >= 0]\n",
    "df['Purchase Amount (USD)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f45bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store cleaned dataset back to .csv file\n",
    "df.to_csv('customer_purchase_dataset_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72ad6d",
   "metadata": {},
   "source": [
    "# Descriptive statistics after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ec4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measures of Central Tendency\n",
    "mean_purchase = df.select_dtypes(include=['float64', 'int64']).mean()\n",
    "median_purchase = df.select_dtypes(include=['float64', 'int64']).median()\n",
    "mode_purchase = df.select_dtypes(include=['float64', 'int64']).mode().iloc[0]\n",
    "\n",
    "print(f\"Mean: {mean_purchase}\")\n",
    "print(f\"Median: {median_purchase}\")\n",
    "print(f\"Mode: {mode_purchase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measures of spread\n",
    "\n",
    "std_dev = df.select_dtypes(include=['float64', 'int64']).std()\n",
    "variance = df.select_dtypes(include=['float64', 'int64']).var()\n",
    "range_v = df.select_dtypes(include=['float64', 'int64']).max() - df.select_dtypes(include=['float64', 'int64']).min()\n",
    "Q1 = df.select_dtypes(include=['float64', 'int64']).quantile(0.25)\n",
    "Q3 = df.select_dtypes(include=['float64', 'int64']).quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Range: {range_v}\")\n",
    "print(f\"IQR: {IQR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e692b4",
   "metadata": {},
   "source": [
    "## Data Visualization and Plotting\n",
    "\n",
    "Data visualization is a crucial component of exploratory data analysis that helps us understand patterns, distributions, and relationships in our dataset through graphical representations.\n",
    "\n",
    "### Why Plotting is Important in EDA:\n",
    "1. **Pattern Recognition**: Visual patterns are easier to identify than numerical summaries\n",
    "2. **Outlier Detection**: Extreme values stand out clearly in plots\n",
    "3. **Distribution Understanding**: Shape, skewness, and spread become apparent\n",
    "4. **Relationship Discovery**: Correlations and associations between variables\n",
    "5. **Data Quality Assessment**: Missing values and inconsistencies are visible\n",
    "\n",
    "### Common Plot Types for Different Data Types:\n",
    "\n",
    "**Numerical Data:**\n",
    "- **Histograms**: Show distribution shape and frequency\n",
    "- **Box Plots**: Display quartiles, median, and outliers\n",
    "- **Density Plots (KDE)**: Smooth distribution curves\n",
    "- **Scatter Plots**: Relationships between two numerical variables\n",
    "- **Line Plots**: Time series or ordered data trends\n",
    "\n",
    "**Categorical Data:**\n",
    "- **Bar Charts**: Frequency of categories\n",
    "- **Pie Charts**: Proportions of categories\n",
    "- **Count Plots**: Similar to bar charts with seaborn\n",
    "\n",
    "**Mixed Data Types:**\n",
    "- **Violin Plots**: Combine box plots with density plots\n",
    "- **Heatmaps**: Correlation matrices or cross-tabulations\n",
    "- **Pair Plots**: Multiple scatter plots for all variable combinations\n",
    "\n",
    "### Key Plotting Libraries:\n",
    "- **Matplotlib**: Foundation plotting library with fine control\n",
    "- **Seaborn**: Statistical plotting with attractive defaults\n",
    "- **Pandas Plotting**: Quick plots directly from DataFrames\n",
    "- **Plotly**: Interactive visualizations\n",
    "\n",
    "### Statistical Information in Plots:\n",
    "Our current dataset analysis shows:\n",
    "- **Mean vs Median**: Close values suggest relatively normal distributions\n",
    "- **Skewness**: Most variables show slight right-skew (positive values)\n",
    "- **IQR**: Interquartile ranges help identify outliers in box plots\n",
    "- **Standard Deviation**: Indicates spread around the mean\n",
    "\n",
    "The following cells will demonstrate various plotting techniques to visualize our customer purchase dataset effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple bar chart for Gender column\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(df['Gender'].value_counts().index, df['Gender'].value_counts().values)\n",
    "plt.title('Gender Distribution')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301097ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple line graph - Age trend (sorted by age)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot 1: Line graph\n",
    "plt.subplot(1, 2, 1)\n",
    "df_sorted = df.sort_values('Age')\n",
    "plt.plot(df_sorted['Age'], df_sorted['Purchase Amount (USD)'], linewidth=0.8, alpha=0.7)\n",
    "plt.title('Purchase Amount Trend by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Purchase Amount (USD)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Scatter plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(df['Age'], df['Purchase Amount (USD)'], alpha=0.6, s=30)\n",
    "plt.title('Age vs Purchase Amount (Scatter)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Purchase Amount (USD)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20478c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set basic style\n",
    "plt.style.use('default')\n",
    "\n",
    "# Create simple plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Simple Data Visualizations', fontsize=14)\n",
    "\n",
    "# 1. Age histogram\n",
    "axes[0, 0].hist(df['Age'], bins=15, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Age Distribution')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# 2. Purchase amount by gender\n",
    "df.boxplot(column='Purchase Amount (USD)', by='Gender', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Purchase Amount by Gender')\n",
    "\n",
    "# 3. Category counts\n",
    "category_counts = df['Category'].value_counts()\n",
    "axes[1, 0].bar(category_counts.index, category_counts.values)\n",
    "axes[1, 0].set_title('Product Categories')\n",
    "axes[1, 0].set_xlabel('Category')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "\n",
    "# 4. Age vs Purchase Amount\n",
    "axes[1, 1].scatter(df['Age'], df['Purchase Amount (USD)'], alpha=0.6)\n",
    "axes[1, 1].set_title('Age vs Purchase Amount')\n",
    "axes[1, 1].set_xlabel('Age')\n",
    "axes[1, 1].set_ylabel('Purchase Amount (USD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b43373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plots using plotly\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# Histogram of Age\n",
    "fig = px.histogram(df, x='Age', nbins=15, title='Age Distribution')\n",
    "fig.show()\n",
    "\n",
    "# Line plot of Purchase Amount over Age\n",
    "fig = px.line(df.sort_values('Age'), x='Age', y='Purchase Amount (USD)', title='Purchase Amount Trend by Age')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Shapes (skewness and kurtosis)\n",
    "\n",
    "# https://www.datacamp.com/tutorial/understanding-skewness-and-kurtosis\n",
    "\n",
    "# What is skewness and kurtosis?\n",
    "# Skewness measures the asymmetry of the data distribution. A skewness value > 0 indicates a right-skewed distribution, while a value < 0 indicates a left-skewed distribution.\n",
    "# Kurtosis measures the \"tailedness\" of the data distribution. A kurtosis value > 3 indicates a distribution with heavier tails than a normal distribution, while a value < 3 indicates lighter tails.  \n",
    "\n",
    "\n",
    "skewness = df.select_dtypes(include=['float64', 'int64']).skew()\n",
    "kurtosis = df.select_dtypes(include=['float64', 'int64']).kurtosis()\n",
    "\n",
    "print(f\"Skewness: {skewness}\")\n",
    "print(f\"Kurtosis: {kurtosis}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the kde plots to visualize the distribution with mean, median and mode markers\n",
    "# Also mention the kind of distribution (normal, left-skewed, right-skewed, etc.)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(df[col], fill=True)\n",
    "    plt.axvline(mean_purchase[col], color='r', linestyle='--', label='Mean')\n",
    "    plt.axvline(median_purchase[col], color='g', linestyle='-', label='Median')\n",
    "    plt.axvline(mode_purchase[col], color='b', linestyle=':', label='Mode')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Density')\n",
    "    if skewness[col] > 0:\n",
    "        skew_type = \"Right-Skewed\"\n",
    "    elif skewness[col] < 0:\n",
    "        skew_type = \"Left-Skewed\"\n",
    "    else:\n",
    "        skew_type = \"Symmetric\"\n",
    "    plt.text(0.05, 0.95, f'Skew: {skewness[col]:.2f} ({skew_type})\\nKurtosis: {kurtosis[col]:.2f}', \n",
    "             transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "    # transform=plt.gca().transAxes to place text in axes coordinates\n",
    "    # It works by transforming the coordinates of the text box from data coordinates to axes coordinates, allowing for consistent placement regardless of the data range.\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa061df",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773cd2a",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Hypothesis testing is a statistical method used to make inferences or draw conclusions about a population based on a sample of data. It involves formulating a null hypothesis (H₀) and an alternative hypothesis (H₁), collecting data, and using statistical tests to determine whether to reject or fail to reject the null hypothesis.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Null Hypothesis (H₀):**\n",
    "- A statement that there is no effect or no difference between groups or variables\n",
    "- Serves as a starting point for statistical testing\n",
    "- Typically assumed to be true until evidence suggests otherwise\n",
    "\n",
    "**Alternative Hypothesis (H₁):**\n",
    "- A statement that contradicts the null hypothesis\n",
    "- Suggests that there is an effect or a difference between groups or variables\n",
    "- Represents the research hypothesis that the researcher aims to support through data analysis\n",
    "\n",
    "### Example Hypothesis Test\n",
    "\n",
    "**Null Hypothesis (H₀):** The average purchase amount for customers with a subscription is equal to the average purchase amount for customers without a subscription.\n",
    "\n",
    "**Alternative Hypothesis (H₁):** The average purchase amount for customers with a subscription is different from the average purchase amount for customers without a subscription.\n",
    "\n",
    "### Statistical Significance\n",
    "- **p-value**: Probability of observing the test results under the assumption that the null hypothesis is correct\n",
    "- **Significance level (α)**: Threshold for determining statistical significance (commonly 0.05)\n",
    "- **Decision rule**: If p-value < α, reject H₀; otherwise, fail to reject H₀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549fef3",
   "metadata": {},
   "source": [
    "## T-Test Theory and Explanation\n",
    "\n",
    "The **t-test** is a statistical hypothesis test used to determine if there is a significant difference between the means of two groups. It's one of the most commonly used statistical tests in data analysis and research.\n",
    "\n",
    "### What is a T-Test?\n",
    "\n",
    "A t-test compares the means of two groups to determine whether they are statistically different from each other. It uses the t-distribution, which is similar to the normal distribution but accounts for the uncertainty that comes with smaller sample sizes.\n",
    "\n",
    "### Types of T-Tests\n",
    "\n",
    "**1. One-Sample T-Test:**\n",
    "- Compares a sample mean to a known population mean\n",
    "- Example: Is the average age of our customers significantly different from 30 years?\n",
    "\n",
    "**2. Independent Two-Sample T-Test (Unpaired):**\n",
    "- Compares the means of two independent groups\n",
    "- Example: Is there a difference in purchase amounts between subscribers and non-subscribers?\n",
    "\n",
    "**3. Paired T-Test (Dependent):**\n",
    "- Compares means from the same subjects at different times\n",
    "- Example: Customer satisfaction before and after a service improvement\n",
    "\n",
    "### Key Components of T-Test\n",
    "\n",
    "**T-Statistic Formula:**\n",
    "```\n",
    "t = (mean₁ - mean₂) / (pooled standard error)\n",
    "```\n",
    "\n",
    "**Degrees of Freedom (df):**\n",
    "- For independent t-test: df = n₁ + n₂ - 2\n",
    "- Where n₁ and n₂ are the sample sizes of the two groups\n",
    "\n",
    "**P-Value:**\n",
    "- Probability of observing the test results under the null hypothesis\n",
    "- If p-value < α (significance level), reject the null hypothesis\n",
    "\n",
    "### Assumptions of T-Test\n",
    "\n",
    "1. **Independence:** Observations must be independent of each other\n",
    "2. **Normality:** Data should be approximately normally distributed\n",
    "3. **Equal Variances:** Both groups should have similar variances (for independent t-test)\n",
    "4. **Continuous Data:** The dependent variable should be continuous\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "**Statistical Significance:**\n",
    "- **p-value < 0.05:** Statistically significant difference (reject H₀)\n",
    "- **p-value ≥ 0.05:** No statistically significant difference (fail to reject H₀)\n",
    "\n",
    "**Effect Size:**\n",
    "- A large t-statistic (positive or negative) indicates a larger difference between groups\n",
    "- The magnitude tells us about practical significance, not just statistical significance\n",
    "\n",
    "### Example from Our Analysis\n",
    "\n",
    "In our customer dataset analysis:\n",
    "- **Groups:** Customers with subscription vs. without subscription\n",
    "- **Variable:** Purchase Amount (USD)\n",
    "- **T-statistic:** 0.0019 (very small)\n",
    "- **P-value:** 0.9985 (very high)\n",
    "- **Conclusion:** No statistically significant difference in purchase amounts between the two groups\n",
    "\n",
    "### When to Use T-Test vs Other Tests\n",
    "\n",
    "**Use T-Test when:**\n",
    "- Comparing means of continuous variables\n",
    "- Sample size is relatively small (< 30) or population standard deviation is unknown\n",
    "- Data meets the assumptions listed above\n",
    "\n",
    "**Consider alternatives when:**\n",
    "- Data is not normally distributed → Use Mann-Whitney U test\n",
    "- Comparing more than two groups → Use ANOVA\n",
    "- Large sample sizes → Z-test might be appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7899ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis Testing Example\n",
    "\n",
    "# Null Hypothesis (H0): There is no significant difference in average purchase amount between customers with and without a subscription.\n",
    "# Alternative Hypothesis (H1): There is a significant difference in average purchase amount between customers with and without a subscription.\n",
    "\n",
    "from scipy import stats\n",
    "# Separate the data into two groups\n",
    "group_with_subscription = df[df['Subscription Status'] == 'Yes']['Purchase Amount (USD)']\n",
    "group_without_subscription = df[df['Subscription Status'] == 'No']['Purchase Amount (USD)']\n",
    "\n",
    "# Perform independent t-test\n",
    "t_stat, p_value = stats.ttest_ind(group_with_subscription, group_without_subscription)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis.\")\n",
    "    # This suggests that there could be a significant difference in average purchase amounts between the two groups.\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis.\")\n",
    "    # This suggests that there is no significant difference in average purchase amounts between the two groups.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
