{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30424c7a",
   "metadata": {},
   "source": [
    "# Introduction to Generative AI\n",
    "\n",
    "## What is Generative AI?\n",
    "\n",
    "Generative AI refers to artificial intelligence systems that can create new content, data, or outputs that resemble human-created work. Unlike traditional AI systems that primarily analyze and classify existing data, generative AI models learn patterns from training data to produce novel, original content.\n",
    "\n",
    "## Discriminative vs Generative Models\n",
    "\n",
    "| **Discriminative Models** | **Generative Models** |\n",
    "|---------------------------|----------------------|\n",
    "| **Purpose**: Classify or predict labels for given inputs | **Purpose**: Generate new data samples similar to training data |\n",
    "| **Question**: \"What is this?\" | **Question**: \"What could this be?\" |\n",
    "| **Examples**: Image classifiers, spam detectors, sentiment analysis | **Examples**: GPT models, DALL-E, Stable Diffusion |\n",
    "| **Output**: Categories, labels, or predictions | **Output**: New text, images, code, audio, or other content |\n",
    "| **Learning**: Learns decision boundaries between classes | **Learning**: Learns underlying data distribution and patterns |\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "### ü§ñ Chatbots and Conversational AI\n",
    "- **Customer service automation**\n",
    "- **Virtual assistants** (ChatGPT, Claude, Bard)\n",
    "- **Educational tutoring systems**\n",
    "- **Mental health support bots**\n",
    "\n",
    "### üé® Image and Visual Content Generation\n",
    "- **Art creation** (DALL-E, Midjourney, Stable Diffusion)\n",
    "- **Photo editing and enhancement**\n",
    "- **Product design and prototyping**\n",
    "- **Marketing content creation**\n",
    "\n",
    "### üíª Code Assistants and Development Tools\n",
    "- **Code completion** (GitHub Copilot, CodeT5)\n",
    "- **Bug detection and fixing**\n",
    "- **Documentation generation**\n",
    "- **Code translation between programming languages**\n",
    "- **Architecture and design suggestions**\n",
    "\n",
    "### üìù Additional Applications\n",
    "- **Content writing** (blogs, articles, creative writing)\n",
    "- **Music and audio generation**\n",
    "- **Video creation and editing**\n",
    "- **3D model generation**\n",
    "- **Scientific research and drug discovery**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b716e",
   "metadata": {},
   "source": [
    "## Generative Models Overview\n",
    "\n",
    "### Generative Adversarial Networks (GANs)\n",
    "\n",
    "**GANs** consist of two neural networks competing against each other:\n",
    "\n",
    "- **Generator**: Creates fake data samples\n",
    "- **Discriminator**: Tries to distinguish real from fake data\n",
    "\n",
    "The generator learns to create increasingly realistic data by trying to fool the discriminator, while the discriminator becomes better at detecting fakes. This adversarial training process results in high-quality generated content.\n",
    "\n",
    "**Key Characteristics:**\n",
    "- Excellent for generating realistic images\n",
    "- Fast inference once trained\n",
    "- Can suffer from mode collapse and training instability\n",
    "- Examples: StyleGAN, CycleGAN, Pix2Pix\n",
    "\n",
    "### Variational Autoencoders (VAEs)\n",
    "\n",
    "**VAEs** learn to encode data into a compressed latent space and then decode it back to the original format.\n",
    "\n",
    "**Architecture:**\n",
    "- **Encoder**: Maps input data to a probability distribution in latent space\n",
    "- **Latent Space**: Compressed representation with probabilistic properties\n",
    "- **Decoder**: Reconstructs data from latent representations\n",
    "\n",
    "**Key Characteristics:**\n",
    "- Provides smooth interpolation between data points\n",
    "- More stable training than GANs\n",
    "- Lower quality outputs compared to GANs\n",
    "- Useful for data compression and anomaly detection\n",
    "\n",
    "### Diffusion Models (Stable Diffusion)\n",
    "\n",
    "**Diffusion models** learn to reverse a gradual noising process by progressively denoising data.\n",
    "\n",
    "**Process:**\n",
    "1. **Forward Process**: Gradually add noise to training data\n",
    "2. **Reverse Process**: Learn to remove noise step by step\n",
    "3. **Generation**: Start with pure noise and iteratively denoise\n",
    "\n",
    "**Key Characteristics:**\n",
    "- State-of-the-art quality for image generation\n",
    "- Highly controllable with text prompts\n",
    "- Slower generation compared to GANs\n",
    "- Examples: DALL-E 2, Stable Diffusion, Midjourney\n",
    "\n",
    "### Comparison Summary\n",
    "\n",
    "| Model Type | Quality | Speed | Training Stability | Control |\n",
    "|------------|---------|-------|-------------------|---------|\n",
    "| **GANs** | High | Fast | Moderate | Limited |\n",
    "| **VAEs** | Moderate | Fast | High | Good |\n",
    "| **Diffusion** | Very High | Slow | High | Excellent |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390a0f3",
   "metadata": {},
   "source": [
    "## Large Language Models (LLMs)\n",
    "\n",
    "### Architecture Basics: Transformers\n",
    "\n",
    "**Transformers** are the foundational architecture behind modern LLMs, introduced in the paper \"Attention Is All You Need\" (2017).\n",
    "\n",
    "**Key Components:**\n",
    "- **Self-Attention Mechanism**: Allows the model to weigh the importance of different words in a sequence\n",
    "- **Multi-Head Attention**: Multiple attention mechanisms running in parallel\n",
    "- **Position Encoding**: Provides information about word order since transformers don't inherently understand sequence\n",
    "- **Feed-Forward Networks**: Process the attention outputs\n",
    "- **Layer Normalization**: Stabilizes training\n",
    "\n",
    "**Architecture Types:**\n",
    "- **Encoder-Only**: Processes input sequences (BERT)\n",
    "- **Decoder-Only**: Generates sequences autoregressively (GPT)\n",
    "- **Encoder-Decoder**: Combines both for translation tasks (T5)\n",
    "\n",
    "### Pre-trained Models\n",
    "\n",
    "#### GPT (Generative Pre-trained Transformer)\n",
    "- **Architecture**: Decoder-only transformer\n",
    "- **Training**: Autoregressive language modeling (predict next word)\n",
    "- **Versions**: GPT-1 (117M params) ‚Üí GPT-4 (1.76T params estimated)\n",
    "- **Strengths**: Text generation, conversation, code completion\n",
    "\n",
    "#### LLaMA (Large Language Model Meta AI)\n",
    "- **Architecture**: Decoder-only transformer with optimizations\n",
    "- **Training**: Efficient training on diverse datasets\n",
    "- **Versions**: LLaMA 1 (7B-65B params), LLaMA 2 (7B-70B params)\n",
    "- **Strengths**: Open-source alternative, efficient inference\n",
    "\n",
    "#### BERT (Bidirectional Encoder Representations from Transformers)\n",
    "- **Architecture**: Encoder-only transformer\n",
    "- **Training**: Masked language modeling + next sentence prediction\n",
    "- **Versions**: BERT-Base (110M), BERT-Large (340M)\n",
    "- **Strengths**: Understanding context, classification tasks\n",
    "\n",
    "### Use Cases in Natural Language Processing\n",
    "\n",
    "#### üìù Text Generation and Completion\n",
    "- **Creative writing** and storytelling\n",
    "- **Email drafting** and professional communication\n",
    "- **Code generation** and programming assistance\n",
    "- **Content creation** for marketing and social media\n",
    "\n",
    "#### üîç Text Analysis and Understanding\n",
    "- **Sentiment analysis** for customer feedback\n",
    "- **Named entity recognition** (people, places, organizations)\n",
    "- **Text classification** and categorization\n",
    "- **Question answering** systems\n",
    "\n",
    "#### üåê Language Translation and Processing\n",
    "- **Machine translation** between languages\n",
    "- **Text summarization** for long documents\n",
    "- **Paraphrasing** and style transfer\n",
    "- **Grammar correction** and language learning\n",
    "\n",
    "#### ü§ñ Conversational AI Applications\n",
    "- **Chatbots** for customer service\n",
    "- **Virtual assistants** for task automation\n",
    "- **Educational tutoring** and personalized learning\n",
    "- **Research assistance** and information retrieval\n",
    "\n",
    "#### üíº Business and Enterprise Applications\n",
    "- **Document processing** and information extraction\n",
    "- **Contract analysis** and legal document review\n",
    "- **Meeting transcription** and summary generation\n",
    "- **Knowledge management** and search enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f810bb4",
   "metadata": {},
   "source": [
    "## Prompt Engineering\n",
    "\n",
    "### What is Prompt Engineering?\n",
    "\n",
    "**Prompt engineering** is the practice of designing and optimizing input prompts to elicit the best possible responses from large language models. It's a crucial skill for effectively leveraging AI systems to achieve specific goals and outcomes.\n",
    "\n",
    "**Key Principles:**\n",
    "- **Clarity**: Be specific and unambiguous in your instructions\n",
    "- **Context**: Provide relevant background information\n",
    "- **Structure**: Use consistent formatting and organization\n",
    "- **Iteration**: Refine prompts based on model responses\n",
    "\n",
    "### Writing Effective Prompts\n",
    "\n",
    "#### üéØ Components of a Good Prompt\n",
    "\n",
    "1. **Task Description**: Clearly state what you want the model to do\n",
    "2. **Context**: Provide necessary background information\n",
    "3. **Instructions**: Specify format, tone, and constraints\n",
    "4. **Examples**: Show desired input-output patterns (when applicable)\n",
    "5. **Output Format**: Define how you want the response structured\n",
    "\n",
    "#### ‚úÖ Best Practices\n",
    "\n",
    "- **Be specific**: Instead of \"Write about dogs,\" use \"Write a 200-word informative article about dog training techniques for puppies\"\n",
    "- **Use clear language**: Avoid ambiguous terms and jargon\n",
    "- **Set constraints**: Specify length, style, audience, and format requirements\n",
    "- **Provide context**: Give the model relevant background information\n",
    "- **Use positive framing**: Say what you want, not what you don't want\n",
    "\n",
    "### Prompting Techniques\n",
    "\n",
    "#### üöÄ Zero-Shot Prompting\n",
    "\n",
    "**Definition**: Asking the model to perform a task without providing any examples.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Classify the following email as spam or not spam:\n",
    "\"Congratulations! You've won $1,000,000! Click here to claim your prize now!\"\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Simple, well-defined tasks\n",
    "- When you don't have examples available\n",
    "- For general knowledge questions\n",
    "\n",
    "#### üìö Few-Shot Prompting\n",
    "\n",
    "**Definition**: Providing a few examples of input-output pairs before asking the model to perform the task.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Classify these emails as spam or not spam:\n",
    "\n",
    "Email: \"Meeting scheduled for tomorrow at 2 PM in conference room A\"\n",
    "Classification: Not spam\n",
    "\n",
    "Email: \"URGENT: Verify your account immediately or it will be deleted!\"\n",
    "Classification: Spam\n",
    "\n",
    "Email: \"Your order #12345 has been shipped and will arrive in 2-3 business days\"\n",
    "Classification: Not spam\n",
    "\n",
    "Email: \"Make money fast! Work from home and earn $5000/week!\"\n",
    "Classification: ?\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Complex or nuanced tasks\n",
    "- When you have good examples available\n",
    "- For tasks requiring specific formatting\n",
    "\n",
    "#### üß† Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "**Definition**: Encouraging the model to break down complex problems into step-by-step reasoning.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Solve this math word problem step by step:\n",
    "\n",
    "Sarah has 15 apples. She gives 1/3 of them to her brother and 2/5 of the remaining apples to her sister. How many apples does Sarah have left?\n",
    "\n",
    "Let me think through this step by step:\n",
    "1. Sarah starts with 15 apples\n",
    "2. She gives 1/3 to her brother: 15 √ó 1/3 = 5 apples\n",
    "3. Remaining after giving to brother: 15 - 5 = 10 apples\n",
    "4. She gives 2/5 of remaining to sister: 10 √ó 2/5 = 4 apples\n",
    "5. Final amount: 10 - 4 = 6 apples\n",
    "\n",
    "Therefore, Sarah has 6 apples left.\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Mathematical problems\n",
    "- Complex reasoning tasks\n",
    "- Multi-step processes\n",
    "- When you need to understand the model's reasoning\n",
    "\n",
    "### Hands-on with Open-Source LLM APIs\n",
    "\n",
    "#### ü§ó Hugging Face Transformers\n",
    "\n",
    "**Popular Models Available:**\n",
    "- **Text Generation**: GPT-2, GPT-Neo, BLOOM, LLaMA\n",
    "- **Text Classification**: BERT, RoBERTa, DistilBERT\n",
    "- **Question Answering**: BERT-QA, RoBERTa-QA\n",
    "- **Translation**: MarianMT, T5\n",
    "\n",
    "**Basic Usage Pattern:**\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize a pipeline for specific task\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Use the pipeline with your prompt\n",
    "result = generator(\"Your prompt here\", max_length=100)\n",
    "```\n",
    "\n",
    "#### üîß API Integration Best Practices\n",
    "\n",
    "- **Rate Limiting**: Respect API rate limits and implement backoff strategies\n",
    "- **Error Handling**: Account for timeouts, server errors, and quota limits\n",
    "- **Cost Management**: Monitor usage and optimize prompt efficiency\n",
    "- **Security**: Keep API keys secure and never commit them to version control\n",
    "- **Version Control**: Track which model versions you're using for reproducibility\n",
    "\n",
    "#### üéõÔ∏è Parameter Tuning\n",
    "\n",
    "**Key Parameters to Experiment With:**\n",
    "- **Temperature**: Controls randomness (0.0 = deterministic, 1.0 = very random)\n",
    "- **Max Tokens**: Limits response length\n",
    "- **Top-p**: Nucleus sampling parameter\n",
    "- **Top-k**: Limits vocabulary to top k most likely tokens\n",
    "- **Frequency Penalty**: Reduces repetition\n",
    "- **Presence Penalty**: Encourages topic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24671aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ca34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Theory of Relativity ‚Äì in plain words**\n",
      "\n",
      "Einstein‚Äôs relativity isn‚Äôt one single idea; it‚Äôs two big ideas that changed how we think about space, time and gravity. Think of them as two parts of the same story.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Special Relativity (1905)\n",
      "\n",
      "**Core Idea:**  \n",
      "The laws of physics are the same for every observer who is moving at a constant speed (no acceleration), and the speed of light is always the same, no matter how fast you‚Äôre moving.\n",
      "\n",
      "### Why that matters\n",
      "\n",
      "| Old thinking | New reality (special relativity) |\n",
      "|--------------|-----------------------------------|\n",
      "| Time is absolute: everyone experiences it the same. | Time is relative: it can tick faster or slower depending on how fast you‚Äôre moving. |\n",
      "| Length is the same for everyone. | Length ‚Äúshrinks‚Äù in the direction you‚Äôre moving, but only at speeds close to light. |\n",
      "| Adding speeds like in everyday life: 50‚ÄØkm/h + 50‚ÄØkm/h = 100‚ÄØkm/h. | Adding speeds isn‚Äôt simple because the speed of light (‚âà‚ÄØ300‚ÄØ000‚ÄØkm/s) is the ultimate speed limit. |\n",
      "| Mass stays constant. | A moving object‚Äôs ‚Äúrelativistic mass‚Äù grows the faster it goes, making it harder to accelerate to light speed. |\n",
      "\n",
      "### Simple analogies\n",
      "\n",
      "- **The flashlight trick:** Imagine you‚Äôre on a train moving at half the speed of light and you shine a flashlight straight ahead. To you, the beam moves out at light speed. To someone standing on the platform, it‚Äôs still the same speed, even though the train is moving. That‚Äôs because the speed of light is always the same for everyone, no matter how you‚Äôre moving.\n",
      "\n",
      "- **Time dilation (the ‚Äútwin paradox‚Äù):** Two twins, one stays on Earth, the other travels in a spaceship near light speed. When the traveler returns, he‚Äôs younger. The moving twin‚Äôs clock ‚Äúslowed down‚Äù because of the speed difference.\n",
      "\n",
      "- **Length contraction (the ‚Äúmoving ladder‚Äù):** Picture a ladder that is 10‚ÄØm long when standing still. If you could run it near light speed, a stationary observer would measure it as a bit shorter (only noticeable at extreme speeds).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. General Relativity (1915)\n",
      "\n",
      "**Core Idea:**  \n",
      "Gravity isn‚Äôt a force pulling objects; it‚Äôs the curvature of space‚Äëtime caused by mass and energy. Objects follow the shape of space‚Äëtime, which looks like a ‚Äúdimple‚Äù around a heavy ball.\n",
      "\n",
      "### How it works\n",
      "\n",
      "1. **Space‚Äëtime is a 4‚Äëdimensional fabric** (three spatial dimensions + time).\n",
      "2. **Mass/energy curves this fabric.** Think of a heavy bowling ball placed on a stretched rubber sheet ‚Äì the sheet depresses around the ball.\n",
      "3. **Objects move along the curved paths.** Like a marble rolling on that sheet, it will spiral around the bowling ball because the surface bends toward it.\n",
      "\n",
      "### Everyday effects\n",
      "\n",
      "- **Gravitational time dilation:** Clocks run slightly slower near massive objects (e.g., on Earth) than farther away (e.g., in space). That‚Äôs why GPS satellites must account for relativity to keep their clocks accurate.\n",
      "- **Light bending:** Light travels straight, but the curvature of space‚Äëtime makes its path bend near a massive body. That‚Äôs why stars appear slightly shifted when the Sun is between Earth and the stars (the ‚Äúsolar eclipse‚Äù experiment that first confirmed Einstein‚Äôs theory).\n",
      "- **Black holes:** Extremely dense objects where space‚Äëtime curves so steep that even light can‚Äôt escape.\n",
      "\n",
      "### Simple analogy\n",
      "\n",
      "- **The rubber sheet:** Drop a heavy ball in the middle of a stretched sheet. The sheet sags. If you roll a smaller ball near it, it will start to orbit the heavy ball, not because a ‚Äúforce‚Äù pulls it, but because it‚Äôs following the curved surface. That‚Äôs exactly what gravity does, but in four dimensions.\n",
      "\n",
      "---\n",
      "\n",
      "## Putting It All Together\n",
      "\n",
      "1. **Motion matters:** How fast you‚Äôre moving changes how you experience time and space.\n",
      "2. **Light is the ultimate speed limit:** Nothing can go faster; this constancy forces the weirdness in time and space.\n",
      "3. **Gravity = geometry:** Massive objects warp the fabric of space‚Äëtime, and all motion follows that warped geometry.\n",
      "\n",
      "### Quick ‚Äúreal‚Äëworld‚Äù check\n",
      "\n",
      "- **GPS satellites**: They orbit Earth at high speeds and are far enough away that gravitational time runs faster for them. Engineers need to correct for both effects to keep maps accurate.\n",
      "- **Twin paradox**: While it‚Äôs a thought experiment, we can see time dilation in particle decays: subatomic particles that travel close to light speed live longer than they do at rest.\n",
      "- **Light bending**: The Sun‚Äôs mass deflects starlight by a tiny amount; we can actually measure that shift with very precise instruments.\n",
      "\n",
      "---\n",
      "\n",
      "### Bottom line\n",
      "\n",
      "- **Special Relativity** tells us that motion changes how we measure time and length, and that the speed of light is a universal constant.\n",
      "- **General Relativity** tells us that gravity isn‚Äôt a force pulling objects; it‚Äôs the shape of space‚Äëtime itself bending because of mass and energy.\n",
      "\n",
      "These ideas are the foundation of modern physics, from GPS to black hole imaging. They may sound strange, but they‚Äôre backed by countless experiments and everyday technology.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    input=\"Explain the theory of relativity in simple terms.\"\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "message = response.output_text\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bec5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0507335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The theory of relativity** is a way of understanding how space, time, and gravity work. It‚Äôs actually two closely related ideas that Einstein developed in the early 1900s:\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Special Relativity (1905)\n",
      "\n",
      "| Idea | What it means | Everyday analogy |\n",
      "|------|---------------|------------------|\n",
      "| **The speed of light is the same everywhere** | No matter how fast you‚Äôre moving, light always travels at the same speed (‚âà‚ÄØ300‚ÄØ000‚ÄØkm/s). | Imagine you‚Äôre on a bicycle and a light flash appears behind you. No matter how fast you go, the flash still moves at the same speed relative to *you*. |\n",
      "| **Time can slow down or speed up** | When two clocks are moving relative to each other, the moving clock ticks slower. | Think of a video that‚Äôs slowed down: the moving clock ‚Äúplays‚Äù slower. |\n",
      "| **Lengths can shrink** | Moving objects get shorter in the direction of motion. | A moving train looks a bit ‚Äúsquashed‚Äù if you‚Äôre moving beside it very quickly. |\n",
      "| **Mass and energy are interchangeable** | Energy (E) and mass (m) are linked by \\(E = mc^2\\). | A tiny amount of mass can be turned into a huge amount of energy (like nuclear power). |\n",
      "\n",
      "**Why does this happen?**  \n",
      "Because space and time are not separate, independent things‚Äîthey‚Äôre woven together into a single ‚Äúfabric‚Äù called *spacetime*. Moving through spacetime changes how you experience it.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. General Relativity (1915)\n",
      "\n",
      "Special relativity works well when there‚Äôs no gravity, but in the real world, gravity matters. General relativity tells us how gravity actually works:\n",
      "\n",
      "| Idea | What it means | Everyday analogy |\n",
      "|------|---------------|------------------|\n",
      "| **Gravity is curved spacetime** | Mass (or energy) bends the ‚Äúfabric‚Äù of spacetime, and that bending tells objects how to move. | Imagine a heavy ball on a stretched rubber sheet. The sheet curves around the ball, and a smaller marble rolls toward it‚Äînot because of a ‚Äúforce‚Äù pulling it, but because the sheet is sloped. |\n",
      "| **Time runs slower near massive objects** | Clocks closer to a planet or star tick slower than those farther away. | A clock on the top of a mountain ticks slightly faster than one at sea level. |\n",
      "| **Light follows curved paths** | Light doesn‚Äôt travel in a straight line near massive bodies‚Äîit bends around them. | Think of looking at a distant object behind a large building; the light bends, making the object appear shifted. |\n",
      "\n",
      "**The big picture**:  \n",
      "Mass tells spacetime how to curve, and curved spacetime tells objects (including light) how to move. That‚Äôs why the Earth orbits the Sun, why light from distant stars is bent by galaxies, and why clocks on satellites need to be corrected for both special and general relativity to keep GPS accurate.\n",
      "\n",
      "---\n",
      "\n",
      "## Quick Takeaways\n",
      "\n",
      "1. **Speed of light is a constant** ‚Üí leads to time slowing and lengths shrinking for moving observers.\n",
      "2. **Space and time are one fabric** ‚Üí they change together.\n",
      "3. **Mass bends that fabric** ‚Üí the ‚Äúgravity‚Äù we feel is the result of this bending.\n",
      "4. **Energy ‚Üî Mass** ‚Üí massive energy can be converted into mass and vice versa.\n",
      "\n",
      "### A Simple Thought Experiment\n",
      "\n",
      "- **Twin Paradox**: One twin stays on Earth; the other travels close to the speed of light in a spaceship and returns younger. That‚Äôs because the moving twin‚Äôs clock ran slower (special relativity) and also because of the gravitational effect of the spaceship‚Äôs acceleration (general relativity).\n",
      "\n",
      "---\n",
      "\n",
      "**Bottom line**:  \n",
      "Relativity reshapes our intuition about how things move and interact. It tells us that what we experience as ‚Äútime‚Äù and ‚Äúspace‚Äù is a flexible, interwoven fabric that reacts to energy and mass‚Äîan idea that has stood up to countless experiments and is the backbone of modern physics.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    input=\"Explain the theory of relativity in simple terms.\"\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "message = response.output_text\n",
    "print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
